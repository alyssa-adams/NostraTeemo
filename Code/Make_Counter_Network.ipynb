{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making counter networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the data that was collected in the file \"Get_Data_From_Riot.ipynb\", this code will make several counter networks that represents which champions beat what on different groups of days.\n",
    "\n",
    "The days are grouped in the following way:\n",
    "Say we have days 1,2,3,4 for patch 6.23. Networks will be constructed for day groups {1} {1,2} {1,2,3} {1,2,3,4}, {2} {3} {4}, and finally {2,4}. \n",
    "This is because we only care about groups of days that occur in order. But this enumeration allows us to have networks for each individual day, the entire set of days, and subsets of concurrent days inbetween."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "################## Import packages n shit ##################\n",
    "import pandas as pd\n",
    "import datreant.core as dtr\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "################## CHANGE THE PATCH NAME!!! #########################\n",
    "# Set up path and tree names\n",
    "net = dtr.Tree('Data/Networks/Challenger_Network_Patch6_24')\n",
    "net.make()\n",
    "# Find the matches in the patch I want\n",
    "matches = dtr.discover('Data/Matches/Challenger_Patch6_24/')\n",
    "# Find which days are in there\n",
    "days = matches.categories['Day']\n",
    "# Find unique days and keep order\n",
    "indexes = np.unique(days, return_index=True)[1]\n",
    "sorteddays = [days[index] for index in sorted(indexes)]\n",
    "# Make an arbitrary list for a loop (probably not needed, I just suck at Python)\n",
    "indices = list(range(0, len(sorteddays)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "################## Three different loops to make the networks I want #########################\n",
    "################## Loop 1: Over each single day #########################\n",
    "\n",
    "for day in sorteddays:\n",
    "\n",
    "    # Make the patch name for each treant, a folder for days 1-10 or something\n",
    "    ################## CHANGE THE PATCH NAME!!! #########################\n",
    "    path0 = 'Data/Networks/Challenger_Network_Patch6_24/days' + str(day) + '-' + str(day)\n",
    "    thesedays = [day]\n",
    "    m0 = dtr.Treant(path0)\n",
    "    m0.path\n",
    "\n",
    "    ################## CHANGE THE PATCH NAME!!! #########################\n",
    "    # Write the categories, the patch number, which days, and number of days\n",
    "    m0.categories['Patch'] = '6_24'\n",
    "    m0.categories['Number of Days'] = len(thesedays)\n",
    "    m0.categories['Dates'] = str(thesedays)\n",
    "\n",
    "    # Then get the matches of each corresponding day group\n",
    "    groups = matches.categories.groupby(\"Day\")\n",
    "    data = dtr.Bundle([dtr.Bundle([dtr.Bundle([groups[i] for i in groups if (i in thesedays)]).categories.groupby('Map')['Map.summoners_rift']]).categories.groupby('Queue')['Queue.ranked_solo_queue']])\n",
    "    norm = len(data)\n",
    "\n",
    "    ################## Makes the edges for the graph out of existing champions in that data set ##################\n",
    "    def lots_of_edges(match):\n",
    "        df = pd.read_csv(match['match.csv'].abspath)\n",
    "        df = df[['Champion','Win']]\n",
    "        winners = df[df['Win'] == True]\n",
    "        winners_names = list(winners['Champion'].unique())\n",
    "        losers = df[df['Win'] == False]\n",
    "        losers_names = list(losers['Champion'].unique())\n",
    "        mixwinnerslosers = pd.DataFrame(columns=['Champion','Win'])\n",
    "        for winner in winners_names:\n",
    "            df1 = pd.DataFrame({df.keys()[0]: [winner]*5, df.keys()[1]: [losers_names[0], losers_names[1], losers_names[2], losers_names[3], losers_names[4]]})\n",
    "            mixwinnerslosers = pd.concat([mixwinnerslosers,df1])\n",
    "        return mixwinnerslosers\n",
    "\n",
    "    edges = pd.DataFrame(columns=['Champion','Win'])\n",
    "    for match in data:\n",
    "        df2 = lots_of_edges(match)\n",
    "        edges = pd.concat([edges,df2])\n",
    "\n",
    "    # Fix column names\n",
    "    tally = edges.groupby(edges.columns.tolist()).size().reset_index().rename(columns={0:'Weight'})\n",
    "    tally.rename(columns={'Champion':'Champion A'}, inplace=True)\n",
    "    tally.rename(columns={'Win':'Champion B'}, inplace=True)\n",
    "\n",
    "    ################## For each edge, determine the weight as outlined in the lines below this cell ##################\n",
    "    network = pd.DataFrame(columns=['Champion A','Champion B', 'Weight'])\n",
    "    championsA = list(tally['Champion A'].unique())\n",
    "    championsB = list(tally['Champion B'].unique())\n",
    "    for champb in championsB:\n",
    "        for champa in championsA:\n",
    "            AB = tally.loc[tally['Champion B'] == champb].loc[tally['Champion A'] == champa]\n",
    "            BA = tally.loc[tally['Champion A'] == champb].loc[tally['Champion B'] == champa]\n",
    "            if len(AB) == 1 and len(BA) == 1:\n",
    "                wA = AB['Weight'].iloc[0]\n",
    "                wB = BA['Weight'].iloc[0]\n",
    "                AB['Weight'] = [(wA/(wA+wB))*((wA+wB)/(norm))]\n",
    "                BA['Weight'] = [(wB/(wA+wB))*((wA+wB)/(norm))]\n",
    "            elif len(AB) == 1 and len(BA) == 0: \n",
    "                AB['Weight'] = [1*((wA+wB)/(norm))]\n",
    "            elif len(AB) == 0 and len(BA) == 1: \n",
    "                BA['Weight'] = [1*((wA+wB)/(norm))]\n",
    "            network = pd.concat([network,AB])\n",
    "            network = pd.concat([network,BA])\n",
    "\n",
    "    ################## Now save this to a .csv file under the treant ##################\n",
    "    m0.draw()\n",
    "    m0['network.csv']\n",
    "    filename = \"network.csv\"\n",
    "    network.to_csv(m0[filename].abspath)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "################## Loop 2: Over last half of the days #########################\n",
    "\n",
    "# Make the patch name for each treant, a folder for days 1-10 or something\n",
    "################## CHANGE THE PATCH NAME!!! #########################\n",
    "thesedays = sorteddays[-int(round(len(sorteddays)/2)):]\n",
    "path0 = 'Data/Networks/Challenger_Network_Patch6_24/days' + str(thesedays[0]) + '-' + str(thesedays[-1:][0])\n",
    "m0 = dtr.Treant(path0)\n",
    "m0.path\n",
    "\n",
    "################## CHANGE THE PATCH NAME!!! #########################\n",
    "# Write the categories, the patch number, which days, and number of days\n",
    "m0.categories['Patch'] = '6_24'\n",
    "m0.categories['Number of Days'] = len(thesedays)\n",
    "m0.categories['Dates'] = str(thesedays)\n",
    "\n",
    "# Then get the matches of each corresponding day group\n",
    "groups = matches.categories.groupby(\"Day\")\n",
    "data = dtr.Bundle([dtr.Bundle([dtr.Bundle([groups[i] for i in groups if (i in thesedays)]).categories.groupby('Map')['Map.summoners_rift']]).categories.groupby('Queue')['Queue.ranked_solo_queue']])\n",
    "norm = len(data)\n",
    "\n",
    "################## Makes the edges for the graph out of existing champions in that data set ##################\n",
    "def lots_of_edges(match):\n",
    "    df = pd.read_csv(match['match.csv'].abspath)\n",
    "    df = df[['Champion','Win']]\n",
    "    winners = df[df['Win'] == True]\n",
    "    winners_names = list(winners['Champion'].unique())\n",
    "    losers = df[df['Win'] == False]\n",
    "    losers_names = list(losers['Champion'].unique())\n",
    "    mixwinnerslosers = pd.DataFrame(columns=['Champion','Win'])\n",
    "    for winner in winners_names:\n",
    "        df1 = pd.DataFrame({df.keys()[0]: [winner]*5, df.keys()[1]: [losers_names[0], losers_names[1], losers_names[2], losers_names[3], losers_names[4]]})\n",
    "        mixwinnerslosers = pd.concat([mixwinnerslosers,df1])\n",
    "    return mixwinnerslosers\n",
    "\n",
    "edges = pd.DataFrame(columns=['Champion','Win'])\n",
    "for match in data:\n",
    "    df2 = lots_of_edges(match)\n",
    "    edges = pd.concat([edges,df2])\n",
    "\n",
    "# Fix column names\n",
    "tally = edges.groupby(edges.columns.tolist()).size().reset_index().rename(columns={0:'Weight'})\n",
    "tally.rename(columns={'Champion':'Champion A'}, inplace=True)\n",
    "tally.rename(columns={'Win':'Champion B'}, inplace=True)\n",
    "\n",
    "################## For each edge, determine the weight as outlined in the lines below this cell ##################\n",
    "network = pd.DataFrame(columns=['Champion A','Champion B', 'Weight'])\n",
    "championsA = list(tally['Champion A'].unique())\n",
    "championsB = list(tally['Champion B'].unique())\n",
    "for champb in championsB:\n",
    "    for champa in championsA:\n",
    "        AB = tally.loc[tally['Champion B'] == champb].loc[tally['Champion A'] == champa]\n",
    "        BA = tally.loc[tally['Champion A'] == champb].loc[tally['Champion B'] == champa]\n",
    "        if len(AB) == 1 and len(BA) == 1:\n",
    "            wA = AB['Weight'].iloc[0]\n",
    "            wB = BA['Weight'].iloc[0]\n",
    "            AB['Weight'] = [(wA/(wA+wB))*((wA+wB)/(norm))]\n",
    "            BA['Weight'] = [(wB/(wA+wB))*((wA+wB)/(norm))]\n",
    "        elif len(AB) == 1 and len(BA) == 0: \n",
    "            AB['Weight'] = [1*((wA+wB)/(norm))]\n",
    "        elif len(AB) == 0 and len(BA) == 1: \n",
    "            BA['Weight'] = [1*((wA+wB)/(norm))]\n",
    "        network = pd.concat([network,AB])\n",
    "        network = pd.concat([network,BA])\n",
    "\n",
    "################## Now save this to a .csv file under the treant ##################\n",
    "m0.draw()\n",
    "m0['network.csv']\n",
    "filename = \"network.csv\"\n",
    "network.to_csv(m0[filename].abspath)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "################## Loop 3: Over day 1-x #########################\n",
    "\n",
    "indices = list(range(1, len(sorteddays)))\n",
    "for index in indices:\n",
    "\n",
    "    # Make the patch name for each treant, a folder for days 1-10 or something\n",
    "    ################## CHANGE THE PATCH NAME!!! #########################\n",
    "    thesedays = sorteddays[0:index+1]\n",
    "    path0 = 'Data/Networks/Challenger_Network_Patch6_24/days' + str(thesedays[0]) + '-' + str(thesedays[-1:][0])\n",
    "    m0 = dtr.Treant(path0)\n",
    "    m0.path\n",
    "\n",
    "    ################## CHANGE THE PATCH NAME!!! #########################\n",
    "    # Write the categories, the patch number, which days, and number of days\n",
    "    m0.categories['Patch'] = '6_24'\n",
    "    m0.categories['Number of Days'] = len(thesedays)\n",
    "    m0.categories['Dates'] = str(thesedays)\n",
    "\n",
    "    # Then get the matches of each corresponding day group\n",
    "    groups = matches.categories.groupby(\"Day\")\n",
    "    data = dtr.Bundle([dtr.Bundle([dtr.Bundle([groups[i] for i in groups if (i in thesedays)]).categories.groupby('Map')['Map.summoners_rift']]).categories.groupby('Queue')['Queue.ranked_solo_queue']])\n",
    "    norm = len(data)\n",
    "\n",
    "    ################## Makes the edges for the graph out of existing champions in that data set ##################\n",
    "    def lots_of_edges(match):\n",
    "        df = pd.read_csv(match['match.csv'].abspath)\n",
    "        df = df[['Champion','Win']]\n",
    "        winners = df[df['Win'] == True]\n",
    "        winners_names = list(winners['Champion'].unique())\n",
    "        losers = df[df['Win'] == False]\n",
    "        losers_names = list(losers['Champion'].unique())\n",
    "        mixwinnerslosers = pd.DataFrame(columns=['Champion','Win'])\n",
    "        for winner in winners_names:\n",
    "            df1 = pd.DataFrame({df.keys()[0]: [winner]*5, df.keys()[1]: [losers_names[0], losers_names[1], losers_names[2], losers_names[3], losers_names[4]]})\n",
    "            mixwinnerslosers = pd.concat([mixwinnerslosers,df1])\n",
    "        return mixwinnerslosers\n",
    "\n",
    "    edges = pd.DataFrame(columns=['Champion','Win'])\n",
    "    for match in data:\n",
    "        df2 = lots_of_edges(match)\n",
    "        edges = pd.concat([edges,df2])\n",
    "\n",
    "    # Fix column names\n",
    "    tally = edges.groupby(edges.columns.tolist()).size().reset_index().rename(columns={0:'Weight'})\n",
    "    tally.rename(columns={'Champion':'Champion A'}, inplace=True)\n",
    "    tally.rename(columns={'Win':'Champion B'}, inplace=True)\n",
    "\n",
    "    ################## For each edge, determine the weight as outlined in the lines below this cell ##################\n",
    "    network = pd.DataFrame(columns=['Champion A','Champion B', 'Weight'])\n",
    "    championsA = list(tally['Champion A'].unique())\n",
    "    championsB = list(tally['Champion B'].unique())\n",
    "    for champb in championsB:\n",
    "        for champa in championsA:\n",
    "            AB = tally.loc[tally['Champion B'] == champb].loc[tally['Champion A'] == champa]\n",
    "            BA = tally.loc[tally['Champion A'] == champb].loc[tally['Champion B'] == champa]\n",
    "            if len(AB) == 1 and len(BA) == 1:\n",
    "                wA = AB['Weight'].iloc[0]\n",
    "                wB = BA['Weight'].iloc[0]\n",
    "                AB['Weight'] = [(wA/(wA+wB))*((wA+wB)/(norm))]\n",
    "                BA['Weight'] = [(wB/(wA+wB))*((wA+wB)/(norm))]\n",
    "            elif len(AB) == 1 and len(BA) == 0: \n",
    "                AB['Weight'] = [1*((wA+wB)/(norm))]\n",
    "            elif len(AB) == 0 and len(BA) == 1: \n",
    "                BA['Weight'] = [1*((wA+wB)/(norm))]\n",
    "            network = pd.concat([network,AB])\n",
    "            network = pd.concat([network,BA])\n",
    "\n",
    "    ################## Now save this to a .csv file under the treant ##################\n",
    "    m0.draw()\n",
    "    m0['network.csv']\n",
    "    filename = \"network.csv\"\n",
    "    network.to_csv(m0[filename].abspath)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If A-->B and B-->A exists, \n",
    "\n",
    "    Change weights of A-->B and B-->A to WAB/WAB+WBA and WBA/WAB+WBA\n",
    "    otherwise\n",
    "    \n",
    "        If A-->B exists while B-->A doesn't,\n",
    "            Change weight to 1\n",
    "            otherwise\n",
    "            \n",
    "                If B-->A exists while A-->B doesn't,\n",
    "                    Change weight to 1\n",
    "\n",
    "    Let's normalize this by multiplying each edge weight by (#AB + #BA)/#Tot\n",
    "    So if A beat B in every single game, then A-->B = WAB/WAB+WBA * (#AB + #BA)/#Tot \n",
    "                                                    = 100/100 * 100/100 = 1\n",
    "                                                    as expected.\n",
    "    B-->A is 0 as expected\n",
    "    If A-->B is 1 out of 100 games, then A-->B = WAB/WAB+WBA * (#AB + #BA)/#Tot \n",
    "                                                    = 1/1 * 1/100 = 1/100\n",
    "                                                    as expected.\n",
    "    If A-->B is 50 and B-->A is 50 out of 100 games, then A-->B = WAB/WAB+WBA * (#AB + #BA)/#Tot \n",
    "                                                    = 50/100 * 100/100 = 1/2\n",
    "                                                    as expected."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
